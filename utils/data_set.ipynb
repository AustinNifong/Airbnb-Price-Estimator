{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('..')))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import string\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Austin/Jupyter/Airbnb_Project/utils'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(category: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\" Get Dataset Algorithm.\n",
    "\n",
    "    Loads and returns a specific dataset from the project folder. \n",
    "    Initially tries utf-8 encoding and if utf-8 does not work,\n",
    "    repeatedly guess other encoding schemes to try and encode the file.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = None\n",
    "    fp = 'data_sets/{name}.csv'.format(name = category)\n",
    "    try:\n",
    "        dataset = pd.read_csv(fp)\n",
    "    except UnicodeDecodeError:\n",
    "        file_size = os.path.getsize(fp)\n",
    "        for byte_size in np.logspace(0, np.log10(file_size), 10).astype('int'):\n",
    "            \n",
    "            try:\n",
    "                with open(fp, 'rb') as rawdata:\n",
    "                    encoding_result = chardet.detect(rawdata.read(byte_size))\n",
    "                encoding_guess = encoding_result['encoding']\n",
    "                print(byte_size, \":\\t\", encoding_guess)\n",
    "                dataset = pd.read_csv(fp, encoding = encoding_guess)\n",
    "                return dataset\n",
    "            except:\n",
    "                continue\n",
    "        raise UnicodeDecodeError\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_useless_columns_listings(listings: pd.core.frame.DataFrame, columns: pd.core.series.Series=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_columns_listings(listings: pd.core.frame.DataFrame, columns: pd.core.series.Series=None) -> None:\n",
    "    '''\n",
    "    Drops useless columns in the listings dataset that will not help machine learning models learn.\n",
    "    These include arbitrary columns such as listing id, listing url, host id, etc.\n",
    "    Many columns are arbitrary but some were selected based on intuition.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # arbitrary_columns consists mostly columns with arbitrary or uninformative values\n",
    "    columns_to_drop = columns if columns else pd.Series([\n",
    "        # the following features are pretty arbitrary\n",
    "        'id', \n",
    "        'listing_url', \n",
    "        'scrape_id',\n",
    "        'last_scraped', \n",
    "        'name',\n",
    "        # 'description', # may actually be useful\n",
    "        # 'neighborhood_overview', # may actually be useful\n",
    "        'picture_url', \n",
    "        'host_id', \n",
    "        'host_url',\n",
    "        'host_name', \n",
    "        'host_since', # may actually be useful?\n",
    "        'host_location', \n",
    "        # 'host_about', # may actually be useful?\n",
    "        'host_neighbourhood',\n",
    "        'host_thumbnail_url', \n",
    "        'host_picture_url',\n",
    "        'host_verifications',\n",
    "        'host_has_profile_pic',\n",
    "        'calendar_last_scraped', \n",
    "        'number_of_reviews_ltm', \n",
    "        'number_of_reviews_l30d', \n",
    "        'first_review',\n",
    "        'last_review', \n",
    "        'license',\n",
    "        'calculated_host_listings_count',\n",
    "        'calculated_host_listings_count_entire_homes',\n",
    "        'calculated_host_listings_count_private_rooms',\n",
    "        'calculated_host_listings_count_shared_rooms', \n",
    "        'reviews_per_month',\n",
    "        'host_listings_count',\n",
    "        'host_total_listings_count',\n",
    "        'minimum_minimum_nights',\n",
    "        'maximum_minimum_nights', \n",
    "        'minimum_maximum_nights',\n",
    "        'maximum_maximum_nights', \n",
    "        'minimum_nights_avg_ntm',\n",
    "        'maximum_nights_avg_ntm',\n",
    "        'maximum_nights',\n",
    "        'minimum_nights',\n",
    "        'has_availability', # this just True or False for one particular day\n",
    "        'host_acceptance_rate',\n",
    "        'host_identity_verified',\n",
    "        'availability_30',\n",
    "        'availability_60',\n",
    "        'availability_90',\n",
    "        'availability_365',\n",
    "        'instant_bookable',\n",
    "        \n",
    "        # the following features are somewhat redundant\n",
    "        'neighbourhood', # We already have GPS coordinates\n",
    "        'neighbourhood_cleansed',\n",
    "        'neighbourhood_group_cleansed',\n",
    "        'review_scores_accuracy', # we already have the average overall rating\n",
    "        'review_scores_checkin',\n",
    "        'review_scores_cleanliness',\n",
    "        'review_scores_communication',\n",
    "        'review_scores_location',\n",
    "        'review_scores_value',\n",
    "        \n",
    "        # the following features have many missing values\n",
    "        'bathrooms', # 0 (fraction that is not nan)\n",
    "        'calendar_updated', # 0\n",
    "        'host_response_time', # 0.573140\n",
    "        'host_response_rate' # 0.573140\n",
    "    ])    \n",
    "    return listings.drop(columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert_column_types(dataset: pd.core.frame.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(dataset: pd.core.frame.DataFrame) -> None:\n",
    "    dataset.rename(columns = {\"bathrooms_text\" : \"bathrooms\"}, inplace = True)\n",
    "    \n",
    "    # appropriate data type for each column\n",
    "    column_dtype_map = {\n",
    "        'latitude' : 'float',\n",
    "        'host_acceptance_rate' : 'float',\n",
    "        'host_is_superhost' : 'bool',\n",
    "        'property_type' : 'category',\n",
    "        'room_type' : 'category',\n",
    "        'bathrooms' : 'float', # will need to process a bit\n",
    "        'bedrooms' : 'float',\n",
    "        'beds' : 'float',\n",
    "        'price' : 'float',\n",
    "        'number_of_reviews' : 'int',\n",
    "        'review_scores_rating' : 'float',\n",
    "        # columns that'll need extra work: amenities\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # format each columns entries\n",
    "    for col in column_dtype_map:\n",
    "        if col not in dataset.columns:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        \n",
    "        if column_dtype_map[col] == 'bool':\n",
    "            '''\n",
    "            bool types in the original dataset is stored as a string ('t' or 'f').\n",
    "\n",
    "            Changes the values to True if 't', False if 'f'.\n",
    "            '''\n",
    "            bool_map = {\n",
    "                't' : True,\n",
    "                'f' : False,\n",
    "                np.nan : np.nan\n",
    "            }\n",
    "            dataset.loc[:, col] = dataset[col].map(lambda b: bool_map[b])\n",
    "            \n",
    "        \n",
    "            \n",
    "        elif col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "            '''\n",
    "            host_response_rate and host_acceptance_rate originally store their values\n",
    "            in a string format (e.g. '51%').\n",
    "\n",
    "            Removes the '%' character so each entry becomes a string'd number (e.g. 51)\n",
    "            so that each entry will have a range from [0, 100].\n",
    "            '''\n",
    "            dataset.loc[:, col] = dataset[col].map(lambda pct: pct if isinstance(pct, float) else pct[:len(pct) - 1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        elif col == 'bathrooms':\n",
    "            '''\n",
    "            bathrooms_text contains the number of bathrooms as a string\n",
    "            (e.g. 1 bathroom, half bath, 3.5 baths, etc.).\n",
    "\n",
    "            Extracts the number of bathrooms from the text.\n",
    "            '''\n",
    "            for i in range(len(dataset[col])):\n",
    "                # if entry is null\n",
    "                if isinstance(dataset[col][i], float):\n",
    "                    continue\n",
    "                    \n",
    "                # gets the string'd number\n",
    "                elif dataset[col][i][0].isdigit():\n",
    "                    dataset.loc[i, col] = dataset[col][i].split()[0]\n",
    "                    \n",
    "                # if the entry doesn't start with a number, then it must be a half bathroom\n",
    "                else:\n",
    "                    dataset.loc[i, col] = '0.5'\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "        elif col == 'price':\n",
    "            '''\n",
    "            price is originally formatted as a string (e.g. '$1,500.00')\n",
    "            where all the prices have 0 cents.\n",
    "\n",
    "            Extracts the total dollar amount as a string (e.g. 1500)\n",
    "            '''\n",
    "            dataset.loc[:, col] = dataset[col].map(lambda price: price[:-3].translate(str.maketrans('', '', string.punctuation)))\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Now that all the entries are formatted correctly,\n",
    "        we convert them to the appropriate data types\n",
    "        '''\n",
    "        dataset.loc[:, col] = dataset[col].astype(column_dtype_map[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill_na_listings(train: pd.core.frame.DataFrame, test: pd.core.frame.DataFrame) -> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_na_neighbourhood(dataset: pd.core.frame.DataFrame) -> None:\n",
    "    # split into data and targets\n",
    "    locations = dataset[['latitude', 'longitude']]\n",
    "    neighbourhoods = dataset['neighbourhood']\n",
    "    \n",
    "    # get training data and labels\n",
    "    train_x = locations.loc[neighbourhoods.notnull()]\n",
    "    train_y = neighbourhoods.loc[neighbourhoods.notnull()]\n",
    "    \n",
    "    # locations with no neighbourhoods\n",
    "    test_x = locations.loc[neighbourhoods.isnull()]\n",
    "    \n",
    "    # predict neighbourhoods\n",
    "    pred_y = KNeighborsClassifier(weights = 'distance').fit(train_x, train_y).predict(test_x)\n",
    "    \n",
    "    # impute neighbourhoods\n",
    "    dataset.loc[dataset.neighbourhood.isnull(), 'neighbourhood'] = pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
